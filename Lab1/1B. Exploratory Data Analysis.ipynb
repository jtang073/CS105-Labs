{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1w8TUMWepGn8"
   },
   "source": [
    "### Exploratory Data Analysis \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YPxq2h1ypGn8"
   },
   "source": [
    "The HOUSES dataset contains a collection of recent real estate listings in San Luis Obispo county and around it. The dataset is as a CSV file. The dataset contains the following fields:\n",
    "\n",
    "1. MLS: Multiple listing service number for the house (unique ID).\n",
    "2. Location: city/town where the house is located. Most locations are in San Luis Obispo county and northern Santa Barbara county (Santa Maria-Orcutt, Lompoc, Guadelupe, Los Alamos), but there some out of area locations as well.\n",
    "4. Price: the most recent listing price of the house (in dollars).\n",
    "5. Bedrooms: number of bedrooms.\n",
    "6. Bathrooms: number of bathrooms.\n",
    "7. Size: size of the house in square feet.\n",
    "8. Price/SQ.ft: price of the house per square foot.\n",
    "9. Status: type of sale. Thee types are represented in the dataset: Short Sale, Foreclosure and Regular.\n",
    "\n",
    "Lets import the required libraries that we will be using later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bPYuP08hpGn9"
   },
   "outputs": [],
   "source": [
    "from numpy import * # everything \n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xwIOGRdbpGoA"
   },
   "source": [
    "Let's load the dataset into a pandas dataframe and have a look at the headers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CYmpXRazpGoB",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.csv', sep=',', error_bad_lines=False) # read fie as a dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LFCfmALtpGoD"
   },
   "source": [
    "Lets take a look at the first 2 rows of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "syVb3mhNpGoE",
    "outputId": "024618c6-0ad0-44cd-8dda-34c403375e2c"
   },
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KcC01DnkpGoH"
   },
   "source": [
    "Examine the provided columns, does the pandas infered datatype of each column make sense? Inlucde your code and/or comments below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rdDcmJeZpGoI"
   },
   "outputs": [],
   "source": [
    "#TODO -- Done\n",
    "print(df.MLS.head(2))\n",
    "print(df.Location.head(2))\n",
    "print(df.Price.head(2))\n",
    "print(df.Bedrooms.head(2))\n",
    "print(df.Bathrooms.head(2))\n",
    "print(df.Size.head(2))\n",
    "print(df['Price/SQ.Ft'].head(2))\n",
    "print(df.Status.head(2))\n",
    "#Yes the infered datatype of each column does make sense since all numbers have dtype of int64 (and float64 for decimals) and those with strings have dtype of object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qfzj_GNXpGoK"
   },
   "source": [
    "Next, lets look at a specific column or feature in the dataframe. \n",
    "Based on the provided dataset, what are the distinct number of bedrooms and bathrooms?  Hint : Use the unique function https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.unique.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s7ADQPLdpGoL"
   },
   "outputs": [],
   "source": [
    "# TODO -- Done\n",
    "print(\"Bedrooms\", pd.unique(df.Bedrooms))\n",
    "print(\"Bathrooms\", pd.unique(df.Bathrooms))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H0g9LnoopGoN"
   },
   "source": [
    "What if we want to drop a column from the dataframe, like the 'Location' column. Hint: Use the drop function https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.drop.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QnEX3TAYpGoN"
   },
   "outputs": [],
   "source": [
    "# TODO -- Done\n",
    "df = df.drop(columns=['Location'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YS2YZbYfpGoQ"
   },
   "source": [
    "Let's rename the first column. \n",
    "\n",
    "Hint: A Google search for 'python pandas dataframe rename' points you at this documentation \n",
    "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.rename.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bMLS4IqOpGoQ",
    "outputId": "243a1af0-bfe1-42d6-f14a-c2a247d1a214"
   },
   "outputs": [],
   "source": [
    "print (\"Before rename\", df.columns)\n",
    "#TODO -- Done\n",
    "\n",
    "df = df.rename(columns={\"MLS\": \"notMLS\"})\n",
    "print (\"After rename\", df.columns)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pc9BF6glpGoT"
   },
   "source": [
    "What is the max, min, mean/avg, and standard deviation of the column 'Bedrooms'?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uGqcmuVvpGoT",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TODO -- Done\n",
    "print(\"Max\", df.Bedrooms.max())\n",
    "print(\"Min\", df.Bedrooms.min())\n",
    "print(\"Mean\", df.Bedrooms.mean())\n",
    "print(\"Average\", df.Bedrooms.sum()/df.Bedrooms.size)\n",
    "print(\"Standard Deviation\", df.Bedrooms.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mM2PDyNdpGoV"
   },
   "source": [
    "Plot the distribution of 'Price/SQ.Ft' using matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kesFl8bqpGoW",
    "outputId": "bc938c95-1380-4d22-9cb1-ad733e0cfd93",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.mlab as mlab\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# plot histogram \n",
    "n, bins, patches = plt.hist(df['Price/SQ.Ft'], 10, facecolor='green')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LdyKhDu8pGoY"
   },
   "source": [
    "One of the best ways to inspect data is visualize it. One way to do this is by using a scatter plot. A scatter plot of the data puts one feature along the x-axis and another along the y-axis, and draws a dot for each data point. \n",
    "\n",
    "Since its difficult to visualize more than 2 or 3 features, one possibility is to use a pair plot that looks at all possible pairs of features. The pair plot shows the interaction of each pair of features inorder to visualize any correlation between features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OnKU2n7UpGoY",
    "outputId": "3d3212e4-b05c-4e10-8b76-5f2691768ff5",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import the scatter_matrix functionality\n",
    "import random as rand\n",
    "from pandas.tools.plotting import scatter_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print (df.shape)\n",
    "x = df.iloc[:,[1,2,3,4,5]] # extract only a subset of columns from dataframe (using index)\n",
    "y = x.dropna(thresh=5) # drop any rows that have 5 or more fields as NAN  \n",
    "a = pd.scatter_matrix(x, alpha=0.05, figsize=(5,5), diagonal='hist')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iTkPFkqKpGob",
    "outputId": "c51c4b9b-bd51-40cf-c09f-d171c5e905db"
   },
   "outputs": [],
   "source": [
    "#Lets plot the Price vs Size of the homes\n",
    "\n",
    "fig=plt.figure()\n",
    "plt.scatter(df.Price, df.Size)\n",
    "axis = fig.gca() #get current axis\n",
    "axis.set_title('Price vs Size')\n",
    "axis.set_xlabel('Price')\n",
    "axis.set_ylabel('Size')\n",
    "fig.canvas.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2V6PqV9vpGod"
   },
   "source": [
    "What does the visualizations and the statistics we observed tell you so far. Is there any other interesting stats or visualizations you think might be helpful. Include your comments and code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QYPCsN2qpGod"
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CrXkvHQ0pGof"
   },
   "source": [
    "## Categorical Encoding\n",
    "If we have categorical or continuous variables and we would like to encode them into discrete integer files (like 0, 1, 2, ...) we can use several tricks in pandas to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VENbjEV6pGof",
    "outputId": "0f81db8f-9823-4115-892c-a6b9254efef7"
   },
   "outputs": [],
   "source": [
    "# Approach 1 - Pandas makes it easy for us to directly replace the text values with their numeric equivalent by using replace .\n",
    "\n",
    "newValues = {\"Status\": {\"Foreclosure\": 1, \"Short Sale\": 2, \"Regular\" : 3}}\n",
    "df2 = df.replace(newValues, inplace=False )\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yMyW7cjspGoi",
    "outputId": "60e95b56-bbb1-4b27-90ee-bbcf43daa2e2"
   },
   "outputs": [],
   "source": [
    "# Approach 2 - Another approach to encoding categorical values is to use a technique called label encoding.\n",
    "# Label encoding is simply converting each value in a column to a number.\n",
    "\n",
    "# One trick you can use in pandas is to convert a column to a category, then use those category \n",
    "# values for your label encoding. \n",
    "\n",
    "df[\"Status\"] = df[\"Status\"].astype('category')\n",
    "df.dtypes\n",
    "\n",
    "# Then you can assign the encoded variable to a new column using the cat.codes accessor.\n",
    "df[\"Status_cat\"] = df[\"Status\"].cat.codes\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yEr05kWSpGok",
    "outputId": "7b87163a-8746-436f-f44a-f65631ee3559"
   },
   "outputs": [],
   "source": [
    "\"\"\"Approach 3 - Label encoding has the advantage that it is straightforward but it has the \n",
    "   disadvantage that the numeric values can be “misinterpreted” by the algorithms. For example, \n",
    "   the value of 1 is obviously less than the value of 3 but does that really correspond to the data set in real life?\n",
    "   For example, is \"Foreclosure\" =1 closer to \"Short Sale\" =2 compared to \"Regular\" =3?\n",
    "\n",
    "   A common alternative approach is called one hot encoding. The basic strategy is to convert each category value \n",
    "   into a new column and assigns a 1 or 0 (True/False) value to the column. This has the benefit of not weighting \n",
    "   a value improperly but does have the downside of adding more columns to the data set.\n",
    "\n",
    "   Pandas supports this feature using get_dummies. This function is named this way because it creates \n",
    "   dummy/indicator variables (aka 1 or 0).\"\"\"\n",
    "\n",
    "pd.get_dummies(df, columns=[\"Status\"], prefix=[\"new\"]).head()\n",
    "\n",
    "# basically, it creates a 3 new columns (one for each unique value in the column.) with the prefix \"new_\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2L8Z7JNMpGom"
   },
   "source": [
    "# Submission Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JoTBnXuepGon"
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Upload the .ipyn notbook to iLearn.\n",
    "\n",
    "Have the TA check your lab to obtain credit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VS0plkafpGon"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "1B. Exploratory Data Analysis.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
